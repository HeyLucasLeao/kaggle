{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação de Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skopt import gp_minimize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from mlxtend.classifier import EnsembleVoteClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Functions and Most Important variables/constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "ID = test['PassengerId']\n",
    "SEED = 4\n",
    "IMPUTER = KNNImputer(weights='distance')\n",
    "SCALER = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_title(x):\n",
    "    y = list(x)\n",
    "    if y.index(','):\n",
    "        y = y[y.index(',') + 2:y.index(\" \", y.index(',') + 2)]\n",
    "        return \"\".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_miss(x):\n",
    "    arr = ['Mlle.', 'Mme.', 'Lady.', 'Ms.', 'Dona.']\n",
    "    if x in arr:\n",
    "        x = 'Miss.'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mr(x):\n",
    "    arr = ['Dr.', 'Rev.', 'Col.', 'Major.', 'Capt.', 'the.', 'Jonkheer.', 'Sir.', 'Don.', 'the' , 'Master.']\n",
    "    if x in arr:\n",
    "        x = 'Mr.'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_married(x):\n",
    "    if x == 'Mrs.':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alone(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_age(x):\n",
    "    if x < 18:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Age']] = IMPUTER.fit_transform(train[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train['Name'].apply(search_title) #make a column of titles\n",
    "train['Title'] = train['Title'].apply(to_miss) #separate titles that can go to Miss\n",
    "train['Title'] = train['Title'].apply(to_mr) #separate titles that can go to Mr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_married'] = train['Title'].apply(is_married) #check if the person are married or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['below_age'] = train['Age'].apply(below_age) #check if the passanger is a child or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['family_size'] = train['SibSp'] + train['Parch'] #make a column about the family size on Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_alone'] = train['family_size'].apply(is_alone) #check if the passanger are alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['group_by_age'] = pd.qcut(train['Age'], q=4, labels=[1,2,3,4]).astype(int) #divide age by groups of Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['group_by_fare'] = pd.qcut(train['Fare'], q=4, labels=[1,2,3,4]).astype(int) #divide fare by groups of Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping NaN and Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['PassengerId', 'Cabin', 'Ticket','Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_rows_to_drop = train[train[['Embarked']].isnull().any(axis=1)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(index=embarked_rows_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\miniconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(use_cat_names=True)\n",
    "ohe_train = ohe.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ohe_train.drop(columns='Survived')\n",
    "y = ohe_train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SCALER.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=ohe_train.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Title_Mr.</th>\n",
       "      <th>Title_Mrs.</th>\n",
       "      <th>Title_Miss.</th>\n",
       "      <th>is_married</th>\n",
       "      <th>below_age</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>group_by_age</th>\n",
       "      <th>group_by_fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex_male  Sex_female       Age  SibSp     Parch      Fare  \\\n",
       "0       1.0       1.0         0.0  0.271174  0.125  0.000000  0.014151   \n",
       "1       0.0       0.0         1.0  0.472229  0.125  0.000000  0.139136   \n",
       "2       1.0       0.0         1.0  0.321438  0.000  0.000000  0.015469   \n",
       "3       0.0       0.0         1.0  0.434531  0.125  0.000000  0.103644   \n",
       "4       1.0       1.0         0.0  0.434531  0.000  0.000000  0.015713   \n",
       "..      ...       ...         ...       ...    ...       ...       ...   \n",
       "884     0.5       1.0         0.0  0.334004  0.000  0.000000  0.025374   \n",
       "885     0.0       0.0         1.0  0.233476  0.000  0.000000  0.058556   \n",
       "886     1.0       0.0         1.0  0.367921  0.125  0.333333  0.045771   \n",
       "887     0.0       1.0         0.0  0.321438  0.000  0.000000  0.058556   \n",
       "888     1.0       1.0         0.0  0.396833  0.000  0.000000  0.015127   \n",
       "\n",
       "     Embarked_S  Embarked_C  Embarked_Q  Title_Mr.  Title_Mrs.  Title_Miss.  \\\n",
       "0           1.0         0.0         0.0        1.0         0.0          0.0   \n",
       "1           0.0         1.0         0.0        0.0         1.0          0.0   \n",
       "2           1.0         0.0         0.0        0.0         0.0          1.0   \n",
       "3           1.0         0.0         0.0        0.0         1.0          0.0   \n",
       "4           1.0         0.0         0.0        1.0         0.0          0.0   \n",
       "..          ...         ...         ...        ...         ...          ...   \n",
       "884         1.0         0.0         0.0        1.0         0.0          0.0   \n",
       "885         1.0         0.0         0.0        0.0         0.0          1.0   \n",
       "886         1.0         0.0         0.0        0.0         0.0          1.0   \n",
       "887         0.0         1.0         0.0        1.0         0.0          0.0   \n",
       "888         0.0         0.0         1.0        1.0         0.0          0.0   \n",
       "\n",
       "     is_married  below_age  family_size  is_alone  group_by_age  group_by_fare  \n",
       "0           0.0        0.0          0.1       0.0      0.000000       0.000000  \n",
       "1           1.0        0.0          0.1       0.0      1.000000       1.000000  \n",
       "2           0.0        0.0          0.0       1.0      0.333333       0.333333  \n",
       "3           1.0        0.0          0.1       0.0      0.666667       1.000000  \n",
       "4           0.0        0.0          0.0       1.0      0.666667       0.333333  \n",
       "..          ...        ...          ...       ...           ...            ...  \n",
       "884         0.0        0.0          0.0       1.0      0.333333       0.333333  \n",
       "885         0.0        0.0          0.0       1.0      0.000000       0.666667  \n",
       "886         0.0        0.0          0.3       0.0      0.333333       0.666667  \n",
       "887         0.0        0.0          0.0       1.0      0.333333       0.666667  \n",
       "888         0.0        0.0          0.0       1.0      0.666667       0.000000  \n",
       "\n",
       "[889 rows x 19 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, \n",
    "y, \n",
    "random_state=SEED,\n",
    "test_size=0.20, \n",
    "stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=SEED)\n",
    "clf2 = RandomForestClassifier(random_state=SEED)\n",
    "clf3= LGBMClassifier(random_state=SEED, subsample_freq=1)\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest Classifier', 'LGBMClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "Accuracy: 0.79 (+/- 0.03) [Logistic Regression]\n",
      "Accuracy: 0.80 (+/- 0.04) [Random Forest Classifier]\n",
      "Accuracy: 0.83 (+/- 0.03) [LGBMClassifier]\n"
     ]
    }
   ],
   "source": [
    "print('5-fold cross validation:')\n",
    "for clf, label in zip([clf1, clf2, clf3], labels):\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, \n",
    "                                              cv=5, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 (+/- 0.03) [Logistic Regression]\n",
      "Accuracy: 0.80 (+/- 0.04) [Random Forest]\n",
      "Accuracy: 0.83 (+/- 0.03) [LGBMClassifier]\n",
      "Accuracy: 0.84 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,2], voting='soft')\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'LGBMClassifier', 'Ensemble']\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], labels):\n",
    "\n",
    "    scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 2.2436\n",
      "Function value obtained: -0.8279\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 1.3492\n",
      "Function value obtained: -0.8223\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.4997\n",
      "Function value obtained: -0.8110\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 1.5985\n",
      "Function value obtained: -0.7897\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 1.0493\n",
      "Function value obtained: -0.8020\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 0.4308\n",
      "Function value obtained: -0.8021\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 1.7352\n",
      "Function value obtained: -0.8020\n",
      "Current minimum: -0.8279\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 2.2736\n",
      "Function value obtained: -0.8324\n",
      "Current minimum: -0.8324\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 1.7745\n",
      "Function value obtained: -0.8009\n",
      "Current minimum: -0.8324\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 2.3326\n",
      "Function value obtained: -0.7964\n",
      "Current minimum: -0.8324\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.5736\n",
      "Function value obtained: -0.7852\n",
      "Current minimum: -0.8324\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.1670\n",
      "Function value obtained: -0.8212\n",
      "Current minimum: -0.8324\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.2525\n",
      "Function value obtained: -0.8347\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.0349\n",
      "Function value obtained: -0.8279\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.9480\n",
      "Function value obtained: -0.8290\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.1301\n",
      "Function value obtained: -0.8043\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0370\n",
      "Function value obtained: -0.8076\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.6033\n",
      "Function value obtained: -0.8156\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1583\n",
      "Function value obtained: -0.8020\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.3694\n",
      "Function value obtained: -0.8212\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.5443\n",
      "Function value obtained: -0.8178\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.1786\n",
      "Function value obtained: -0.8110\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8846\n",
      "Function value obtained: -0.8257\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.2813\n",
      "Function value obtained: -0.8020\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1004\n",
      "Function value obtained: -0.8088\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.9950\n",
      "Function value obtained: -0.8257\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.9315\n",
      "Function value obtained: -0.7773\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.4756\n",
      "Function value obtained: -0.8066\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.8751\n",
      "Function value obtained: -0.8155\n",
      "Current minimum: -0.8347\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.1645\n",
      "Function value obtained: -0.8066\n",
      "Current minimum: -0.8347\n"
     ]
    }
   ],
   "source": [
    "def search_hyperparams(params):\n",
    "    SEED = 4\n",
    "\n",
    "    max_iter = params[0]\n",
    "    C = params[1]\n",
    "    n_estimators_random_forest = params[2]\n",
    "    learning_rate = params[3]\n",
    "    num_leaves = params[4]\n",
    "    min_child_samples = params[5]\n",
    "    subsample = params[6]\n",
    "    colsample_bytree = params[7]\n",
    "    n_estimators_lgbm = params[8]\n",
    "    \n",
    "    clf1 = LogisticRegression(random_state=SEED, \n",
    "                              max_iter=max_iter, \n",
    "                              C=C)\n",
    "    \n",
    "    clf2 = RandomForestClassifier(random_state=SEED, \n",
    "                                  n_estimators= n_estimators_random_forest)\n",
    "    \n",
    "    clf3= LGBMClassifier(random_state=SEED, \n",
    "                         subsample_freq=1, \n",
    "                         learning_rate=learning_rate,\n",
    "                        num_leaves=num_leaves,\n",
    "                        min_child_samples= min_child_samples,\n",
    "                        subsample= subsample,\n",
    "                        colsample_bytree = colsample_bytree,\n",
    "                        n_estimators = n_estimators_lgbm)\n",
    " \n",
    "    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,2], voting='soft')\n",
    "    \n",
    "    scores = cross_val_score(eclf, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return -scores.mean()\n",
    "\n",
    "space = [\n",
    "(100, 5000), #max_iter Logistic Regression\n",
    "(1e-4, 1e-2, 'log-uniform'), #C Logistic Regression\n",
    "(20, 200), #n_estimators RandomForest\n",
    "(1e-3, 1e-1, 'log-uniform'), #learning rate LGBM\n",
    "(2, 128), #num_leaves LGBM\n",
    "(1, 100), #min_child_samples LGBM\n",
    "(0.05, 1.0), #subsample LGBM\n",
    "(0.1, 1.0), #colsample_bytree LGBM\n",
    "(100, 1000)] #n_estimators LGBM\n",
    "\n",
    "result = gp_minimize(search_hyperparams, \n",
    "space,\n",
    "random_state=SEED, \n",
    "verbose=1,\n",
    "n_calls = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter, C, n_estimators_random_forest, learning_rate, num_leaves, min_child_samples, subsample, colsample_bytree, n_estimators_lgbm = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=SEED, \n",
    "                              max_iter=max_iter, \n",
    "                              C=C)\n",
    "    \n",
    "clf2 = RandomForestClassifier(random_state=SEED, \n",
    "                                  n_estimators= n_estimators_random_forest)\n",
    "    \n",
    "clf3= LGBMClassifier(random_state=SEED, \n",
    "                         subsample_freq=1, \n",
    "                         learning_rate=learning_rate,\n",
    "                        num_leaves=num_leaves,\n",
    "                        min_child_samples= min_child_samples,\n",
    "                        subsample= subsample,\n",
    "                        colsample_bytree = colsample_bytree,\n",
    "                        n_estimators = n_estimators_lgbm)\n",
    " \n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,2], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[LogisticRegression(C=0.0001, max_iter=310,\n",
       "                                                random_state=4),\n",
       "                             RandomForestClassifier(n_estimators=25,\n",
       "                                                    random_state=4),\n",
       "                             LGBMClassifier(colsample_bytree=0.3700059027901569,\n",
       "                                            learning_rate=0.003802615401944056,\n",
       "                                            min_child_samples=9,\n",
       "                                            n_estimators=379, num_leaves=65,\n",
       "                                            random_state=4,\n",
       "                                            subsample=0.45884544564953084,\n",
       "                                            subsample_freq=1)],\n",
       "                       weights=[1, 1, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808988764044944"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = eclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQMAAAEGCAYAAABhHPB4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQB0lEQVR4nO3de7hUdbnA8e/LNoybYKL5JJpiyEVTTJJKTewokYGIWUeKykva8d5F09Iyy1KP1FOZpZiXTpaldcy0zIy8pKGIKKJHUfOSmSkXRbIU9uY9f+wftCHYDMaaBfj9PM9+9syatWe948h3z1ozsycyE0nqUvcAktYOxkASYAwkFcZAEmAMJBUb1D1AR7FBt4yuveoeQ6th58Fb1T2CVsMTTzzOnDlzYkWXrV0x6NqLDQd+oO4xtBpuu+PbdY+g1bDb8GErvczdBEmAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMZBUGANJgDGQVBgDSYAxkFQYA0mAMVgjzj/tQzwx+UymXfm5pcs23qg71373GGZe/QWu/e4x9OnVbZmf2WXIViy485uM23tok6dVZ55//nnG/+eB7LTDIIa+eTC3T5lS90hNU2kMImJURMyKiEci4uQqt1WnH1xzO2OPPm+ZZSccsg83TZ3Fm8d+iZumzuKEQ0YuvaxLl+CM48fy29sfbPaoWoUTPnk8I0eOYsZ9DzL1rhkMGjy47pGaprIYREQLcB7wHmAIMD4ihlS1vTrdNv2PzJv/92WWjR6xI5ddcwcAl11zB2P22nHpZUcdtCc/nzyD2fMWNHVOdW7+/PnceustHHzoYQB07dqVPn361DtUE1X5yGBX4JHMfDQzFwI/BsZWuL21ymab9OKvc14A4K9zXmCzTXoB8IZNe7Pfu3Zi0pW/r3M8rcDjjz1G376bcsRhh/C2YTtz5BEf48UXX6x7rKapMgZbAE92OP/nsmwZEXFEREyLiGnZ+o8Kx6lXZvv3c058H6d+82pyyQKtNVpbW7nn7ukc/vEjuX3a3XTv0YOJ/31W3WM1zQZ1D5CZk4BJAF26b7be/At5du4CNu+7EX+d8wKb991o6S7BW4Zsxf+cdQgAm/Tpybt3357W1sVcc9O9dY4rYIt+/diiXz92HT4cgHHvO5CvGYM14ilgyw7n+5Vlrwq/vHkmE8YMZ+IlNzBhzHCuLf/YB4/+4tJ1Jp0+get+f58hWEtsvvnm9Ou3JQ/NmsV2Awdy0+8mM2jwenmYa4WqjMGdwICI2Ib2CBwEfLDC7dXm+2cezB67DKBvn5488usv8+Xzf8XES27gsrMP5aP7v50/PT2PCZ+5uO4x1YCvf+NcDvnIh1i4cCFb9+/PpO9dUvdITRNV7rtGxL7AN4AW4OLM/Epn63fpvlluOPADlc2jNe+5O79d9whaDbsNH8Zdd02LFV1W6TGDzPwV8KsqtyFpzfAViJIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSgE4+azEiFgBLPpV1yQc1ZjmdmblRxbNJaqKVxiAzezVzEEn1amg3ISJ2j4hDyum+EbFNtWNJarZVxiAiTgNOAj5bFnUFLqtyKEnN18gjg3HAfsCLAJn5F8BdCGk900gMFmZmUg4mRkSPakeSVIdGYnBFRFwA9ImIw4HfAhdWO5akZlvpswlLZObEiNgHeAHYDvhCZt5Q+WSSmmqVMShmAt1o31WYWd04kurSyLMJHwOmAgcABwK3R8ShVQ8mqbkaeWRwIrBzZs4FiIhNgD8AF1c5mKTmauQA4lxgQYfzC8oySeuRzt6b8Kly8hHgjoi4mvZjBmOBe5swm6Qm6mw3YckLi/5Yvpa4urpxJNWlszcqnd7MQSTVa5UHECNiU+AzwPbAa5csz8x3VTiXpCZr5ADiD4EHgW2A04HHgTsrnElSDRqJwSaZeRGwKDNvzsxDAR8VSOuZRl5nsKh8fzoi3gv8BXhddSNJqkMjMTgjInoDnwbOBTYCPlnpVJKarpE3Kl1bTs4H9qp2HEl16exFR+fyzz+I+i8y87g1PcyA/m/g/Mt9RnNdctOs2XWPoNWw4KXWlV7W2SODaWt+FElrq85edPT9Zg4iqV5+iIokwBhIKoyBJKCxv3S0XURMjoj7yvkdI+LU6keT1EyNPDK4kPYPUFkEkJn3AgdVOZSk5mskBt0zc+pyy1b+ZKWkdVIjMZgTEdvyzw9RORB4utKpJDVdI+9NOBqYBAyKiKeAx4AJlU4lqekaeW/Co8De5WPVumTmglX9jKR1TyN/6egLy50HIDO/VNFMkmrQyG7Cix1OvxYYDTxQzTiS6tLIbsLXOp6PiInA9ZVNJKkWr+QViN2Bfmt6EEn1auSYwUz++XcNWoBNAY8XSOuZRo4ZjO5wuhV4JjN90ZG0nuk0BhHRAlyfmYOaNI+kmnR6zCAz24BZEbFVk+aRVJNGdhM2Bu6PiKl0eJoxM/erbCpJTddIDD5f+RSSatdIDPbNzJM6LoiIs4GbqxlJUh0aeZ3BPitY9p41PYikenX2uQlHAkcB/SPi3g4X9QJuq3owSc3V2W7Cj4DrgDOBkzssX5CZ8yqdSlLTdfa5CfNp/0i18c0bR1Jd/OvIkgBjIKkwBpIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSAGMgqTAGkgBjIKkwBpIAYyCpMAaSgMY+a1ENWvjySxz/4TEsWriQttZW9nz3GA4+9mTOOeV4Zt1/D2TSb+ttOemr59KtR8+6xxXt99mJHx3LooUv09bWxu77jObDx5zE1045lpnTptCjZy8APvWVb7HtoDfXPG21KotBRFwMjAaezcwdqtrO2uQ1XTfk65dcRbcePWldtIjjJryXXffYm6M+e8bS/6m+c9apXPWji/jg4cfXPK2g/T476+Kf0a17+312wkfGMGyP/wDgsE+fxh4jx9Q8YfNUuZtwKTCqwutf60TE0t/4ra2LaF20iIhYGoLM5OWXXiKIOsdUBxFBt+4d7rPW9vvs1aiyGGTmLcCr7jMZ29raOHzcCA7YfTDD3jGCwTvtAsDZnzuWA/cYwpOPPcy4CR+rd0gto62tjaPftxfj3zmEnd++J4N2bL/Pvv+tr3LkuD254OzPs3DhyzVPWb3aDyBGxBERMS0ips1/bm7d4/zbWlpauPCqm7jixnt5cOZ0HnvoAQBO+uq5XHHzfWzVfztuvO7n9Q6pZbS0tHDez27kB5Nn8NDMu3n84Qc45BOncuE1f+CbP/kNC+Y/x5UXnVv3mJWrPQaZOSkzh2XmsN4bb1L3OGtMz416M3TX3Zl66+Sly1paWthr33H8/jfX1DiZVqbnRr3ZcdfdmHbr73jdpq8nIujadUNG7j+eh2beXfd4las9BuuT5+fN4W8vzAfg5Zf+wV1TbmbLbd7EU088CrQfM/jDjb9my/4D6hxTHSx/n9095Wa23GYA82Y/A5T77HfX8cYBg+ocsyl8anENmjv7Gc7+7DEsbmtj8eLFjBg1lrftOZLjJ4zm739bQGay7aDt+cRpE+seVcVzs59h4inHsritjcxkj3fvx/ARIzn50AOY/9xcMpP+A7fn2NPOqXvUykVmVnPFEZcDI4C+wDPAaZl5UWc/M3CHoXn+Tyd3torWMi+3La57BK2G4z6wDw/df88Kny6p7JFBZo6v6rolrXkeM5AEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEGANJhTGQBBgDSYUxkAQYA0mFMZAEQGRm3TMsFRGzgSfqnqMCfYE5dQ+h1bK+3mdvzMxNV3TBWhWD9VVETMvMYXXPoca9Gu8zdxMkAcZAUmEMmmNS3QNotb3q7jOPGUgCfGQgqTAGkgBjUKmIGBURsyLikYg4ue55tGoRcXFEPBsR99U9S7MZg4pERAtwHvAeYAgwPiKG1DuVGnApMKruIepgDKqzK/BIZj6amQuBHwNja55Jq5CZtwDz6p6jDsagOlsAT3Y4/+eyTForGQNJgDGo0lPAlh3O9yvLpLWSMajOncCAiNgmIroCBwG/qHkmaaWMQUUysxU4BrgeeAC4IjPvr3cqrUpEXA5MAQZGxJ8j4rC6Z2oWX44sCfCRgaTCGEgCjIGkwhhIAoyBpMIYvEpFxIiIuLac3q+zd1VGRJ+IOOoVbOOLEXFCo8uXW+fSiDhwNba19avxnYZrkjFYz5R3S66WzPxFZp7VySp9gNWOgdYtxmAdUX7zPRgRP4yIByLipxHRvVz2eEScHRHTgfdHxMiImBIR0yPiyojoWdYbVa5jOnBAh+s+OCK+XU6/PiKuiogZ5esdwFnAthFxT0ScU9Y7MSLujIh7I+L0Dtd1SkQ8FBG3AgMbuF2Hl+uZERE/W3Kbir0jYlq5vtFl/ZaIOKfDtj/+7/63VTtjsG4ZCHwnMwcDL7Dsb+u5mfkW4LfAqcDe5fw04FMR8VrgQmAMsAuw+Uq28S3g5szcCXgLcD9wMvDHzByamSdGxEhgAO1v0x4K7BIR74yIXWh/2fVQYF/grQ3cpv/NzLeW7T0AdHzF39ZlG+8Fzi+34TBgfma+tVz/4RGxTQPb0SpsUPcAWi1PZuZt5fRlwHHAxHL+J+X722j/Yyq3RQRAV9pfXjsIeCwzHwaIiMuAI1awjXcBHwHIzDZgfkRsvNw6I8vX3eV8T9rj0Au4KjP/XrbRyHsxdoiIM2jfFelJ+8u3l7giMxcDD0fEo+U2jAR27HA8oXfZ9kMNbEudMAbrluVfO97x/IvlewA3ZOb4jitGxNA1OEcAZ2bmBctt4xOv4LouBfbPzBkRcTAwosNlK7q9ARybmR2jQURs/Qq2rQ7cTVi3bBURby+nPwjcuoJ1bgd2i4g3AUREj4jYDngQ2Doiti3rjV/BzwJMBo4sP9sSEb2BBbT/1l/ieuDQDscitoiIzYBbgP0joltE9KJ9l2RVegFPR8RrgA8td9n7I6JLmbk/MKts+8iyPhGxXUT0aGA7WgVjsG6ZBRwdEQ8AGwPfXX6FzJwNHAxcHhH3UnYRMvMl2ncLflkOID67km0cD+wVETOBu4AhmTmX9t2O+yLinMz8DfAjYEpZ76dAr8ycTvvuygzgOtrfxr0qnwfuAG6jPVgd/QmYWq7rv8pt+B7wf8D08lTiBfgId43wXYvriPIw+NrM3KHuWbR+8pGBJMBHBpIKHxlIAoyBpMIYSAKMgaTCGEgC4P8BNvbsnZges4EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[LogisticRegression(C=0.0001, max_iter=310,\n",
       "                                                random_state=4),\n",
       "                             RandomForestClassifier(n_estimators=25,\n",
       "                                                    random_state=4),\n",
       "                             LGBMClassifier(colsample_bytree=0.3700059027901569,\n",
       "                                            learning_rate=0.003802615401944056,\n",
       "                                            min_child_samples=9,\n",
       "                                            n_estimators=379, num_leaves=65,\n",
       "                                            random_state=4,\n",
       "                                            subsample=0.45884544564953084,\n",
       "                                            subsample_freq=1)],\n",
       "                       weights=[1, 1, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing Age and Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Age']] = IMPUTER.fit_transform(test[['Age']])\n",
    "test[['Fare']] = IMPUTER.fit_transform(test[['Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering on Df Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Title'] = test['Name'].apply(search_title) #make a column of titles\n",
    "test['Title'] = test['Title'].apply(to_miss) #separate titles that can go to Miss\n",
    "test['Title'] = test['Title'].apply(to_mr) #separate titles that can go to Mr.\n",
    "test['is_married'] = test['Title'].apply(is_married) #check if the person are married or not\n",
    "test['below_age'] = test['Age'].apply(below_age) #check if the passanger is a child or not\n",
    "test['family_size'] = test['SibSp'] + test['Parch'] #make a column about the family size on Titanic\n",
    "test['is_alone'] = test['family_size'].apply(is_alone) #check if the passanger are alone\n",
    "test['group_by_age'] = pd.qcut(test['Age'], q=4, labels=[1,2,3,4]).astype(int) #divide age by groups of Quantiles\n",
    "test['group_by_fare'] = pd.qcut(test['Fare'], q=4, labels=[1,2,3,4]).astype(int) #divide fare by groups of Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['PassengerId', 'Ticket', 'Cabin', 'Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoding, Scaling and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\miniconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "test = ohe.fit_transform(test)\n",
    "test = SCALER.fit_transform(test)\n",
    "result = eclf.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.Series(result, index=ID, name='Survived')\n",
    "sub.to_csv(\"results.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
